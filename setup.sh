#!/bin/bash

set -e

echo "üöÄ Installation de l'environnement Python..."
python3 -m venv venv
source venv/bin/activate

echo "üì¶ Installation des d√©pendances..."
pip install --upgrade pip
pip install -r requirements.txt

echo "‚úÖ Containers lanc√©s."
docker ps --filter "name=ollama"

echo ""
read -p "Souhaitez-vous lancer les instances Docker d'Ollama maintenant ? (y/n) " answer
if [[ "$answer" == "y" || "$answer" == "Y" ]]; then

    echo "üßπ Suppression des containers ollama1, ollama2 s'ils existent..."
    docker rm -f ollama1 ollama2 2>/dev/null || true

    echo "üê≥ Lancement des containers Docker Ollama..."
    echo "üöÄ D√©marrage des containers avec 3 CPU max chacun..."
    docker run --name ollama1 --cpus=4 --memory=6g -p 11434:11434 -d ollama/ollama
    docker run --name ollama2 --cpus=4 --memory=6g -p 11435:11434 -d ollama/ollama

    echo "‚è≥ Attente 5 secondes pour d√©marrage des containers..."
    sleep 5

    echo "‚¨áÔ∏è T√©l√©chargement du mod√®le llama3 dans chaque container..."
    docker exec -it ollama1 ollama pull llama3
    docker exec -it ollama2 ollama pull llama3

    echo "‚è≥ T√©l√©chargement et chargement initial du mod√®le sur chaque instance..."

    curl -s -X POST http://localhost:11434/api/pull \
      -H "Content-Type: application/json" \
      -d '{"name": "llama3"}' > /dev/null && echo "‚úÖ Mod√®le charg√© sur port 11434"

    curl -s -X POST http://localhost:11435/api/pull \
      -H "Content-Type: application/json" \
      -d '{"name": "llama3"}' > /dev/null && echo "‚úÖ Mod√®le charg√© sur port 11435"

fi

echo ""
echo "‚úÖ Installation termin√©e."
echo "‚û°Ô∏è Vous pouvez maintenant activer votre environnement avec :"
echo "   source venv/bin/activate"
echo "‚û°Ô∏è Et ex√©cuter :"
echo "   python run.py query.csv -o resultat.csv -i http://localhost:11434 http://localhost:11435"
echo ""
